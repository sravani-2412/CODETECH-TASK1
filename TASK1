import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

def extract_data(file_path):
    """Load data from a CSV file."""
    return pd.read_csv(file_path)

def preprocess_data(df):
    """Handle missing values, encode categorical variables, and standardize numerical features."""
    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns
    categorical_features = df.select_dtypes(include=['object']).columns
    
  
    numeric_transformer = Pipeline([
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler())
    ])
    
    
    categorical_transformer = Pipeline([
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('encoder', OneHotEncoder(handle_unknown='ignore'))
    ])
    
    preprocessor = ColumnTransformer([
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])
    
    df_processed = preprocessor.fit_transform(df)
    return pd.DataFrame(df_processed)

def load_data(df, output_path):
    """Save the processed data to a new CSV file."""
    df.to_csv(output_path, index=False)

def etl_pipeline(input_path, output_path):
    """Execute the full ETL pipeline."""
    df = extract_data(input_path)
    df = preprocess_data(df)
    load_data(df, output_path)
    print(f"ETL process completed. Processed data saved to {output_path}")


if _name_ == "_main_":
    input_csv = "raw_data.csv"  
    output_csv = "processed_data.csv"
    etl_pipeline(input_csv, output_csv)
